{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Finetuning and Prompting\n",
    "\n",
    "In this project, you will first learn how to use Huggingface's Transformers library to load large language models. Next, we will generate text from these models. Finally, we will work with a small text-to-SQL dataset, where the input is a natural language query and the output is a SQL query that can be executed against a database. You will explore (1) finetuning a pretrained language model, and (2) prompting the pretrained language model with examples. \n",
    "\n",
    "This project will be more open ended than the previous projects. We expect you to learn how to use the huggingface and torch documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we install and import the required dependencies. These include:\n",
    "* `torch` for modeling and training\n",
    "* `transformers` for pre-trained models\n",
    "* `datasets` from huggingface to load existing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:32.463796Z",
     "start_time": "2023-10-27T03:33:28.233920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# !pip install transformers datasets sentence-transformers\n",
    "\n",
    "# Standard library imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "os.environ[\"http_proxy\"] = \"http://192.168.235.34:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://192.168.235.34:7890\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, let's verify that we're connected to a GPU runtime and that `torch` can detect the GPU.\n",
    "We'll define a variable `device` here to use throughout the code so that we can easily change to run on CPU for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:35.241977Z",
     "start_time": "2023-10-27T03:33:35.239801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use GPT-2 Medium for this project. This includes both the GPT-2 tokenizer and the GPT-2 model weights itself. If you want to learn more about this model, you can read the GPT-2 paper https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf.\n",
    "\n",
    "Let's first load the tokenizer for the GPT-2 medium model. You can find how to do this by reading the documentation for AutoTokenzier in transformers, and finding the GPT-2 model of ~345 million params in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:36.415521Z",
     "start_time": "2023-10-27T03:33:35.307720Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# Your code here\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token # convenient for padding later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's tokenize and detokenize some text from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:36.633708Z",
     "start_time": "2023-10-27T03:33:36.630187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 995]\n",
      "Hello world\n",
      "[39, 5708, 11, 269, 10205, 5908, 1556, 40138, 47249, 235]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode('Hello world'))\n",
    "print(tokenizer.decode(tokenizer.encode('Hello world')))\n",
    "print(tokenizer.encode(\"Hola, c√≥mo est√°süòç\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the GPT-2 Medium model. Make sure you also put the model onto the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:45.967260Z",
     "start_time": "2023-10-27T03:33:38.683408Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "# Your code here\n",
    "# del finetuned_model\n",
    "model_name='gpt2-medium'\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(model_name).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate From the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some text from the model to test its LM capabilities. Let's first generate one output of length 50 tokens using greedy decoding (temperature = 0), which should get us some text with high likelihood under the model. When generating text, you can condition on phrases such as \"The coolest thing in NLP right now is\". Find the relevant function and arguments to use for generating text using the Huggingface documentation.\n",
    "\n",
    "Hint: you may find https://huggingface.co/docs/transformers/main_classes/text_generation to be useful for learning about generating from LMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:48.196177Z",
     "start_time": "2023-10-27T03:33:45.967550Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/generation/utils.py:1288: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coolest thing right now in NLP is the ability to use the same data to predict the future.\n",
      "\n",
      "The future is always changing, and the data is always changing.\n",
      "\n",
      "The future is always changing, and the data is always changing\n"
     ]
    }
   ],
   "source": [
    "from transformers import GenerationConfig\n",
    "inputs = tokenizer(\"The coolest thing right now in NLP is\", return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "# Your code here\n",
    "generation_config = GenerationConfig.from_pretrained(model_name,max_length=50,temperature=1e-6,do_sample=True)\n",
    "sample_output = gpt2_model.generate(inputs,generation_config,pad_token_id=50256).squeeze(0)\n",
    "\n",
    "# print(sample_output)\n",
    "\n",
    "print(\"{}\".format(tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate 10 pieces of random text of length 50 tokens from the model using random sampling with temperature set to 0.7. This will allow the text to be somewhat higher in diversity (random sampling) while maintaining reasonable quality (temperature < 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:33:58.085156Z",
     "start_time": "2023-10-27T03:33:48.197118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: The coolest thing right now in NLP is that you can actually see what's happening before someone can say anything to you. You can really know where they are. It's really amazing.\n",
      "\n",
      "You know, I think that's one of the\n",
      "1: The coolest thing right now in NLP is the ability to add things like:\n",
      "\n",
      "What's the current time?\n",
      "\n",
      "Which line is the top one? (i.e. 2, 3, 4, 5, 6, 7,\n",
      "2: The coolest thing right now in NLP is the word 'learned', which is an odd thing to say when you've got a language like Japanese where learning is so boring\" ‚Äì David J. D'Amore, author of \"The Science\n",
      "3: The coolest thing right now in NLP is the language that's coming from AI,\" says Mark Muro, a machine learning expert at Google. So that's what we're moving towards. The language we're building is a really natural language. It\n",
      "4: The coolest thing right now in NLP is that it creates a unique form of communication between people. You can't just say 'this is what I'm thinking' and then say 'this is what you're thinking' and then say 'this is\n",
      "5: The coolest thing right now in NLP is machine learning. It's been like a lightning bolt of change in the last few years, and I think that's why it's really cool.\n",
      "\n",
      "M: I think that's why it's such\n",
      "6: The coolest thing right now in NLP is the ability to easily extract and annotate information into an image. The ability to do this means that you can quickly see changes in a data source, like a picture, and then quickly compare them to other\n",
      "7: The coolest thing right now in NLP is that you can combine the data from many sources ‚Äî real world data from your sensors, machine learning algorithms, and data visualization applications ‚Äî and build an intelligent model with each of those. The result is an N\n",
      "8: The coolest thing right now in NLP is that they are using machine learning techniques to generate an artificial neural network, for example, an algorithm that is able to tell the difference between a photograph of a cat that has been taken by a person who is\n",
      "9: The coolest thing right now in NLP is that, from a developer's point of view, you can just do anything you want in this language,\" said Zawinski. \"You can create a program that will tell you what a car is doing\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"The coolest thing right now in NLP is\", return_tensors=\"pt\").input_ids.cuda()\n",
    "# Your code here\n",
    "generation_config = GenerationConfig.from_pretrained(model_name,min_length=50,max_length=50,temperature=0.7,do_sample=True)\n",
    "\n",
    "sample_outputs = [gpt2_model.generate(inputs,generation_config,pad_token_id=50256).squeeze(0) for i in range(10)]\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-to-SQL Task Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's download the data of text-to-SQL pairs and the database against which we'll execute queries to retrieve answers.\n",
    "\n",
    "The code below initializes the database and does some initial preprocessing data preprocessing + splitting for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.045228Z",
     "start_time": "2023-10-27T03:33:58.094244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- MySQL dump 10.13  Distrib 5.7.17, for Linux (x86_64)\n",
      "--\n",
      "-- Host: localhost    Database: geo\n",
      "-- ------------------------------------------------------\n",
      "-- Server version\t5.7.17\n",
      "\n",
      "/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;\n",
      "/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;\n",
      "/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;\n",
      "/*!40101 SET NAMES utf8 */;\n",
      "/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;\n",
      "/*!40103 SET TIME_ZONE='+00:00' */;\n",
      "/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;\n",
      "/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;\n",
      "/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;\n",
      "/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;\n",
      "\n",
      "--\n",
      "-- Table structure for table border_info\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS border_info;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE border_info (\n",
      "  state_name text,\n",
      "  border text\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table border_info\n",
      "--\n",
      "/*!40000 ALTER TABLE border_info DISABLE KEYS */;\n",
      "INSERT INTO border_info VALUES ('alabama','tennessee'),('alabama','georgia'),('alabama','florida'),('alabama','mississippi'),('arizona','utah'),('arizona','colorado'),('arizona','new mexico'),('arizona','california'),('arizona','nevada'),('arkansas','missouri'),('arkansas','tennessee'),('arkansas','mississippi'),('arkansas','louisiana'),('arkansas','texas'),('arkansas','oklahoma'),('california','oregon'),('california','nevada'),('california','arizona'),('colorado','nebraska'),('colorado','kansas'),('colorado','oklahoma'),('colorado','new mexico'),('colorado','arizona'),('colorado','utah'),('colorado','wyoming'),('connecticut','massachusetts'),('connecticut','rhode island'),('connecticut','new york'),('delaware','pennsylvania'),('delaware','new jersey'),('delaware','maryland'),('district of columbia','maryland'),('district of columbia','virginia'),('florida','georgia'),('florida','alabama'),('georgia','north carolina'),('georgia','south carolina'),('georgia','florida'),('georgia','alabama'),('georgia','tennessee'),('idaho','montana'),('idaho','wyoming'),('idaho','utah'),('idaho','nevada'),('idaho','oregon'),('idaho','washington'),('illinois','wisconsin'),('illinois','indiana'),('illinois','kentucky'),('illinois','missouri'),('illinois','iowa'),('indiana','michigan'),('indiana','ohio'),('indiana','kentucky'),('indiana','illinois'),('iowa','minnesota'),('iowa','wisconsin'),('iowa','illinois'),('iowa','missouri'),('iowa','nebraska'),('iowa','south dakota'),('kansas','nebraska'),('kansas','missouri'),('kansas','oklahoma'),('kansas','colorado'),('kentucky','indiana'),('kentucky','ohio'),('kentucky','west virginia'),('kentucky','virginia'),('kentucky','tennessee'),('kentucky','missouri'),('kentucky','illinois'),('louisiana','arkansas'),('louisiana','mississippi'),('louisiana','texas'),('maine','new hampshire'),('maryland','pennsylvania'),('maryland','delaware'),('maryland','virginia'),('maryland','district of columbia'),('maryland','west virginia'),('massachusetts','new hampshire'),('massachusetts','rhode island'),('massachusetts','connecticut'),('massachusetts','new york'),('massachusetts','vermont'),('michigan','ohio'),('michigan','indiana'),('michigan','wisconsin'),('minnesota','wisconsin'),('minnesota','iowa'),('minnesota','south dakota'),('minnesota','north dakota'),('mississippi','tennessee'),('mississippi','alabama'),('mississippi','louisiana'),('mississippi','arkansas'),('missouri','iowa'),('missouri','illinois'),('missouri','kentucky'),('missouri','tennessee'),('missouri','arkansas'),('missouri','oklahoma'),('missouri','kansas'),('missouri','nebraska'),('montana','north dakota'),('montana','south dakota'),('montana','wyoming'),('montana','idaho'),('nebraska','south dakota'),('nebraska','iowa'),('nebraska','missouri'),('nebraska','kansas'),('nebraska','colorado'),('nebraska','wyoming'),('nevada','idaho'),('nevada','utah'),('nevada','arizona'),('nevada','california'),('nevada','oregon'),('new hampshire','maine'),('new hampshire','massachusetts'),('new hampshire','vermont'),('new jersey','new york'),('new jersey','delaware'),('new jersey','pennsylvania'),('new mexico','colorado'),('new mexico','oklahoma'),('new mexico','texas'),('new mexico','arizona'),('new mexico','utah'),('new york','vermont'),('new york','massachusetts'),('new york','connecticut'),('new york','new jersey'),('new york','pennsylvania'),('north carolina','virginia'),('north carolina','south carolina'),('north carolina','georgia'),('north carolina','tennessee'),('north dakota','minnesota'),('north dakota','south dakota'),('north dakota','montana'),('ohio','michigan'),('ohio','pennsylvania'),('ohio','west virginia'),('ohio','kentucky'),('ohio','indiana'),('oklahoma','kansas'),('oklahoma','missouri'),('oklahoma','arkansas'),('oklahoma','texas'),('oklahoma','new mexico'),('oklahoma','colorado'),('oregon','washington'),('oregon','idaho'),('oregon','nevada'),('oregon','california'),('pennsylvania','new york'),('pennsylvania','new jersey'),('pennsylvania','delaware'),('pennsylvania','maryland'),('pennsylvania','west virginia'),('pennsylvania','ohio'),('rhode island','massachusetts'),('rhode island','connecticut'),('south carolina','north carolina'),('south carolina','georgia'),('south dakota','north dakota'),('south dakota','minnesota'),('south dakota','iowa'),('south dakota','nebraska'),('south dakota','wyoming'),('south dakota','montana'),('tennessee','kentucky'),('tennessee','virginia'),('tennessee','north carolina'),('tennessee','georgia'),('tennessee','alabama'),('tennessee','mississippi'),('tennessee','arkansas'),('tennessee','missouri'),('texas','oklahoma'),('texas','arkansas'),('texas','louisiana'),('texas','new mexico'),('utah','wyoming'),('utah','colorado'),('utah','new mexico'),('utah','arizona'),('utah','nevada'),('utah','idaho'),('vermont','new hampshire'),('vermont','massachusetts'),('vermont','new york'),('virginia','maryland'),('virginia','district of columbia'),('virginia','north carolina'),('virginia','tennessee'),('virginia','kentucky'),('virginia','west virginia'),('washington','idaho'),('washington','oregon'),('west virginia','pennsylvania'),('west virginia','maryland'),('west virginia','virginia'),('west virginia','kentucky'),('west virginia','ohio'),('wisconsin','michigan'),('wisconsin','illinois'),('wisconsin','iowa'),('wisconsin','minnesota'),('wyoming','montana'),('wyoming','south dakota'),('wyoming','nebraska'),('wyoming','colorado'),('wyoming','utah'),('wyoming','idaho');\n",
      "/*!40000 ALTER TABLE border_info ENABLE KEYS */;\n",
      "\n",
      "--\n",
      "-- Table structure for table city\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS city;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE city (\n",
      "  city_name text,\n",
      "  population int(11) DEFAULT NULL,\n",
      "  country_name varchar(3) NOT NULL DEFAULT '',\n",
      "  state_name text\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table city\n",
      "--\n",
      "/*!40000 ALTER TABLE city DISABLE KEYS */;\n",
      "INSERT INTO city VALUES ('birmingham',284413,'usa','alabama'),('mobile',200452,'usa','alabama'),('montgomery',177857,'usa','alabama'),('huntsville',142513,'usa','alabama'),('tuscaloosa',75143,'usa','alabama'),('anchorage',174431,'usa','alaska'),('phoenix',789704,'usa','arizona'),('tucson',330537,'usa','arizona'),('mesa',152453,'usa','arizona'),('tempe',106919,'usa','arizona'),('glendale',96988,'usa','arizona'),('scottsdale',88622,'usa','arizona'),('little rock',158915,'usa','arkansas'),('fort smith',71384,'usa','arkansas'),('north little rock',64388,'usa','arkansas'),('los angeles',2966850,'usa','california'),('san diego',875538,'usa','california'),('san francisco',678974,'usa','california'),('san jose',629442,'usa','california'),('long beach',361334,'usa','california'),('oakland',339337,'usa','california'),('sacramento',275741,'usa','california'),('anaheim',219311,'usa','california'),('fresno',218202,'usa','california'),('santa ana',203713,'usa','california'),('riverside',170876,'usa','california'),('huntington beach',170505,'usa','california'),('stockton',149779,'usa','california'),('glendale',139060,'usa','california'),('fremont',131945,'usa','california'),('torrance',131497,'usa','california'),('garden grove',123351,'usa','california'),('san bernardino',118794,'usa','california'),('pasadena',118072,'usa','california'),('east los angeles',110017,'usa','california'),('oxnard',108195,'usa','california'),('modesto',106963,'usa','california'),('sunnyvale',106618,'usa','california'),('bakersfield',105611,'usa','california'),('concord',103763,'usa','california'),('berkeley',103328,'usa','california'),('fullerton',102246,'usa','california'),('inglewood',94162,'usa','california'),('hayward',93585,'usa','california'),('pomona',92742,'usa','california'),('orange',91450,'usa','california'),('ontario',88820,'usa','california'),('santa monica',88314,'usa','california'),('santa clara',87700,'usa','california'),('citrus heights',85911,'usa','california'),('norwalk',84901,'usa','california'),('burbank',84625,'usa','california'),('chula vista',83927,'usa','california'),('santa rosa',83205,'usa','california'),('downey',82602,'usa','california'),('costa mesa',82291,'usa','california'),('compton',81230,'usa','california'),('carson',81221,'usa','california'),('salinas',80479,'usa','california'),('west covina',80292,'usa','california'),('vallejo',80188,'usa','california'),('el monte',79494,'usa','california'),('daly city',78519,'usa','california'),('thousand oaks',77797,'usa','california'),('san mateo',77640,'usa','california'),('simi valley',77500,'usa','california'),('oceanside',76698,'usa','california'),('richmond',74676,'usa','california'),('lakewood',74654,'usa','california'),('santa barbara',74542,'usa','california'),('el cajon',73892,'usa','california'),('ventura',73774,'usa','california'),('westminster',71133,'usa','california'),('whittier',68558,'usa','california'),('south gate',66784,'usa','california'),('alhambra',64767,'usa','california'),('buena park',64165,'usa','california'),('san leandro',63952,'usa','california'),('alameda',63852,'usa','california'),('newport beach',63475,'usa','california'),('escondido',62480,'usa','california'),('irvine',62134,'usa','california'),('mountain view',58655,'usa','california'),('fairfield',58099,'usa','california'),('redondo beach',57102,'usa','california'),('scotts valley',6037,'usa','california'),('denver',492365,'usa','colorado'),('colorado springs',215150,'usa','colorado'),('aurora',158588,'usa','colorado'),('lakewood',113808,'usa','colorado'),('pueblo',101686,'usa','colorado'),('arvada',84576,'usa','colorado'),('boulder',76685,'usa','colorado'),('fort collins',64632,'usa','colorado'),('bridgeport',142546,'usa','connecticut'),('hartford',136392,'usa','connecticut'),('new haven',126089,'usa','connecticut'),('waterbury',103266,'usa','connecticut'),('stamford',102466,'usa','connecticut'),('norwalk',77767,'usa','connecticut'),('new britain',73840,'usa','connecticut'),('west hartford',61301,'usa','connecticut'),('danbury',60470,'usa','connecticut'),('greenwich',59578,'usa','connecticut'),('bristol',57370,'usa','connecticut'),('meriden',57118,'usa','connecticut'),('wilmington',70195,'usa','delaware'),('washington',638333,'usa','district of columbia'),('jacksonville',540920,'usa','florida'),('miami',346865,'usa','florida'),('tampa',271523,'usa','florida'),('st. petersburg',238647,'usa','florida'),('fort lauderdale',153256,'usa','florida'),('orlando',128394,'usa','florida'),('hollywood',117188,'usa','florida'),('miami beach',96298,'usa','florida'),('clearwater',85450,'usa','florida'),('tallahassee',81548,'usa','florida'),('gainesville',81371,'usa','florida'),('kendall',73758,'usa','florida'),('west palm beach',62530,'usa','florida'),('largo',58977,'usa','florida'),('pensacola',57619,'usa','florida'),('atlanta',425022,'usa','georgia'),('columbus',169441,'usa','georgia'),('savannah',141654,'usa','georgia'),('macon',116860,'usa','georgia'),('albany',74425,'usa','georgia'),('honolulu',762874,'usa','hawaii'),('ewa',190037,'usa','hawaii'),('koolaupoko',109373,'usa','hawaii'),('boise',102249,'usa','idaho'),('chicago',3005172,'usa','illinois'),('rockford',139712,'usa','illinois'),('peoria',124160,'usa','illinois'),('springfield',100054,'usa','illinois'),('decatur',93939,'usa','illinois'),('aurora',81293,'usa','illinois'),('joliet',77956,'usa','illinois'),('evanston',73706,'usa','illinois'),('waukegan',67653,'usa','illinois'),('arlington heights',66116,'usa','illinois'),('elgin',63668,'usa','illinois'),('cicero',61232,'usa','illinois'),('oak lawn',60590,'usa','illinois'),('skokie',60278,'usa','illinois'),('champaign',58267,'usa','illinois'),('indianapolis',700807,'usa','indiana'),('fort wayne',172196,'usa','indiana'),('gary',151968,'usa','indiana'),('evansville',130496,'usa','indiana'),('south bend',109727,'usa','indiana'),('hammond',93714,'usa','indiana'),('muncie',77216,'usa','indiana'),('anderson',64695,'usa','indiana'),('terre haute',61125,'usa','indiana'),('des moines',191003,'usa','iowa'),('cedar rapids',110243,'usa','iowa'),('davenport',103254,'usa','iowa'),('sioux city',82003,'usa','iowa'),('waterloo',75985,'usa','iowa'),('dubuque',62321,'usa','iowa'),('wichita',279212,'usa','kansas'),('kansas city',161148,'usa','kansas'),('topeka',118690,'usa','kansas'),('overland park',81784,'usa','kansas'),('louisville',298451,'usa','kentucky'),('lexington',204165,'usa','kentucky'),('new orleans',557515,'usa','louisiana'),('baton rouge',219419,'usa','louisiana'),('shreveport',205820,'usa','louisiana'),('metairie',164160,'usa','louisiana'),('lafayette',80584,'usa','louisiana'),('lake charles',75051,'usa','louisiana'),('kenner',66382,'usa','louisiana'),('monroe',57597,'usa','louisiana'),('portland',61572,'usa','maine'),('baltimore',786775,'usa','maryland'),('silver spring',72893,'usa','maryland'),('dundalk',71293,'usa','maryland'),('bethesda',63022,'usa','maryland'),('boston',562994,'usa','massachusetts'),('worcester',161799,'usa','massachusetts'),('springfield',152319,'usa','massachusetts'),('new bedford',98478,'usa','massachusetts'),('cambridge',95322,'usa','massachusetts'),('brockton',95172,'usa','massachusetts'),('fall river',92574,'usa','massachusetts'),('lowell',92418,'usa','massachusetts'),('quincy',84743,'usa','massachusetts'),('newton',83622,'usa','massachusetts'),('lynn',78471,'usa','massachusetts'),('somerville',77372,'usa','massachusetts'),('framingham',65113,'usa','massachusetts'),('lawrence',63175,'usa','massachusetts'),('waltham',58200,'usa','massachusetts'),('medford',58076,'usa','massachusetts'),('detroit',1203339,'usa','michigan'),('grand rapids',181843,'usa','michigan'),('warren',161134,'usa','michigan'),('flint',159611,'usa','michigan'),('lansing',130414,'usa','michigan'),('sterling heights',108999,'usa','michigan'),('ann arbor',107969,'usa','michigan'),('livonia',104814,'usa','michigan'),('dearborn',90660,'usa','michigan'),('westland',84603,'usa','michigan'),('kalamazoo',79722,'usa','michigan'),('taylor',77568,'usa','michigan'),('saginaw',77508,'usa','michigan'),('pontiac',76715,'usa','michigan'),('st. clair shores',76210,'usa','michigan'),('southfield',75568,'usa','michigan'),('clinton',72400,'usa','michigan'),('royal oak',70893,'usa','michigan'),('dearborn heights',67706,'usa','michigan'),('troy',67102,'usa','michigan'),('waterford',64250,'usa','michigan'),('wyoming',59616,'usa','michigan'),('redford',58441,'usa','michigan'),('farmington hills',58056,'usa','michigan'),('minneapolis',370951,'usa','minnesota'),('st. paul',270230,'usa','minnesota'),('duluth',92811,'usa','minnesota'),('bloomington',81831,'usa','minnesota'),('rochester',57906,'usa','minnesota'),('jackson',202895,'usa','mississippi'),('st. louis',453085,'usa','missouri'),('kansas city',448159,'usa','missouri'),('springfield',133116,'usa','missouri'),('independence',111797,'usa','missouri'),('st. joseph',76691,'usa','missouri'),('columbia',62061,'usa','missouri'),('billings',66842,'usa','montana'),('great falls',56725,'usa','montana'),('omaha',314255,'usa','nebraska'),('lincoln',171932,'usa','nebraska'),('las vegas',164674,'usa','nevada'),('reno',100756,'usa','nevada'),('manchester',90936,'usa','new hampshire'),('nashua',67865,'usa','new hampshire'),('newark',329248,'usa','new jersey'),('jersey city',223532,'usa','new jersey'),('paterson',137970,'usa','new jersey'),('elizabeth',106201,'usa','new jersey'),('trenton',92124,'usa','new jersey'),('woodbridge',90074,'usa','new jersey'),('camden',84910,'usa','new jersey'),('east orange',77878,'usa','new jersey'),('clifton',74388,'usa','new jersey'),('edison',70193,'usa','new jersey'),('cherry hill',68785,'usa','new jersey'),('bayonne',65047,'usa','new jersey'),('middletown',61615,'usa','new jersey'),('irvington',61493,'usa','new jersey'),('albuquerque',331767,'usa','new mexico'),('new york',7071639,'usa','new york'),('buffalo',357870,'usa','new york'),('rochester',241741,'usa','new york'),('yonkers',195351,'usa','new york'),('syracuse',170105,'usa','new york'),('albany',101727,'usa','new york'),('cheektowaga',92145,'usa','new york'),('utica',75632,'usa','new york'),('niagara falls',71384,'usa','new york'),('new rochelle',70794,'usa','new york'),('schenectady',67972,'usa','new york'),('mount vernon',66713,'usa','new york'),('irondequoit',57648,'usa','new york'),('levittown',57045,'usa','new york'),('charlotte',314447,'usa','north carolina'),('greensboro',155642,'usa','north carolina'),('raleigh',149771,'usa','north carolina'),('winston-salem',131885,'usa','north carolina'),('durham',100538,'usa','north carolina'),('high point',64107,'usa','north carolina'),('fayetteville',59507,'usa','north carolina'),('fargo',61308,'usa','north dakota'),('cleveland',573822,'usa','ohio'),('columbus',564871,'usa','ohio'),('cincinnati',385457,'usa','ohio'),('toledo',354635,'usa','ohio'),('akron',237177,'usa','ohio'),('dayton',203371,'usa','ohio'),('youngstown',115436,'usa','ohio'),('canton',93077,'usa','ohio'),('parma',92548,'usa','ohio'),('lorain',75416,'usa','ohio'),('springfield',72563,'usa','ohio'),('hamilton',63189,'usa','ohio'),('lakewood',61963,'usa','ohio'),('kettering',61186,'usa','ohio'),('euclid',59999,'usa','ohio'),('elyria',57504,'usa','ohio'),('oklahoma city',403213,'usa','oklahoma'),('tulsa',360919,'usa','oklahoma'),('lawton',80054,'usa','oklahoma'),('norman',68020,'usa','oklahoma'),('portland',366383,'usa','oregon'),('eugene',105664,'usa','oregon'),('salem',89233,'usa','oregon'),('philadelphia',1688210,'usa','pennsylvania'),('pittsburgh',423938,'usa','pennsylvania'),('erie',119123,'usa','pennsylvania'),('allentown',103758,'usa','pennsylvania'),('scranton',88117,'usa','pennsylvania'),('upper darby',84054,'usa','pennsylvania'),('reading',78686,'usa','pennsylvania'),('bethlehem',70419,'usa','pennsylvania'),('lower merion',59651,'usa','pennsylvania'),('abingdon',59084,'usa','pennsylvania'),('bristol township',58733,'usa','pennsylvania'),('penn hills',57632,'usa','pennsylvania'),('altoona',57078,'usa','pennsylvania'),('providence',156804,'usa','rhode island'),('warwick',87123,'usa','rhode island'),('cranston',71992,'usa','rhode island'),('pawtucket',71204,'usa','rhode island'),('columbia',101229,'usa','south carolina'),('charleston',69855,'usa','south carolina'),('north charleston',62504,'usa','south carolina'),('greenville',58242,'usa','south carolina'),('sioux falls',81343,'usa','south dakota'),('memphis',646356,'usa','tennessee'),('nashville',455651,'usa','tennessee'),('knoxville',175030,'usa','tennessee'),('chattanooga',169728,'usa','tennessee'),('houston',1595138,'usa','texas'),('dallas',904078,'usa','texas'),('san antonio',785880,'usa','texas'),('el paso',425259,'usa','texas'),('fort worth',385164,'usa','texas'),('austin',345496,'usa','texas'),('corpus christi',231999,'usa','texas'),('lubbock',173979,'usa','texas'),('arlington',160123,'usa','texas'),('amarillo',149230,'usa','texas'),('garland',138857,'usa','texas'),('beaumont',118102,'usa','texas'),('pasadena',112560,'usa','texas'),('irving',109943,'usa','texas'),('waco',101261,'usa','texas'),('abilene',98315,'usa','texas'),('wichita falls',94201,'usa','texas'),('laredo',91449,'usa','texas'),('odessa',90027,'usa','texas'),('brownsville',84997,'usa','texas'),('san angelo',73240,'usa','texas'),('richardson',72496,'usa','texas'),('plano',72331,'usa','texas'),('grand prairie',71462,'usa','texas'),('midland',70525,'usa','texas'),('tyler',70508,'usa','texas'),('mesquite',67053,'usa','texas'),('mcallen',67042,'usa','texas'),('longview',62762,'usa','texas'),('port arthur',61195,'usa','texas'),('salt lake city',163034,'usa','utah'),('provo',74111,'usa','utah'),('west valley',72299,'usa','utah'),('ogden',64407,'usa','utah'),('norfolk',266979,'usa','virginia'),('virginia beach',262199,'usa','virginia'),('richmond',219214,'usa','virginia'),('arlington',152599,'usa','virginia'),('newport news',144903,'usa','virginia'),('hampton',122617,'usa','virginia'),('chesapeake',114226,'usa','virginia'),('portsmouth',104577,'usa','virginia'),('alexandria',103217,'usa','virginia'),('roanoke',100427,'usa','virginia'),('lynchburg',66743,'usa','virginia'),('seattle',493846,'usa','washington'),('spokane',171300,'usa','washington'),('tacoma',158501,'usa','washington'),('bellevue',73903,'usa','washington'),('charleston',63968,'usa','west virginia'),('huntington',63684,'usa','west virginia'),('milwaukee',636212,'usa','wisconsin'),('madison',170616,'usa','wisconsin'),('green bay',87899,'usa','wisconsin'),('racine',85725,'usa','wisconsin'),('kenosha',77685,'usa','wisconsin'),('west allis',63982,'usa','wisconsin'),('appleton',58913,'usa','wisconsin'),('casper',51016,'usa','wyoming');\n",
      "/*!40000 ALTER TABLE city ENABLE KEYS */;\n",
      "\n",
      "--\n",
      "-- Table structure for table highlow\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS highlow;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE highlow (\n",
      "  state_name text,\n",
      "  highest_elevation text,\n",
      "  lowest_point text,\n",
      "  highest_point text,\n",
      "  lowest_elevation text\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table highlow\n",
      "--\n",
      "/*!40000 ALTER TABLE highlow DISABLE KEYS */;\n",
      "INSERT INTO highlow VALUES ('alabama','734','gulf of mexico','cheaha mountain','0'),('alaska','6194','pacific ocean','mount mckinley','0'),('arizona','3851','colorado river','humphreys peak','21'),('arkansas','839','ouachita river','magazine mountain','17'),('california','4418','death valley','mount whitney','-85'),('colorado','4399','arkansas river','mount elbert','1021'),('connecticut','725','long island sound','mount frissell','0'),('delaware','135','atlantic ocean','centerville','0'),('district of columbia','125','potomac river','tenleytown','0'),('florida','105','atlantic ocean','walton county','0'),('georgia','1458','atlantic ocean','brasstown bald','0'),('hawaii','4205','pacific ocean','mauna kea','0'),('idaho','3859','snake river','borah peak','216'),('illinois','376','mississippi river','charles mound','85'),('indiana','383','ohio river','franklin township','98'),('iowa','511','mississippi river','ocheyedan mound','146'),('kansas','1231','verdigris river','mount sunflower','207'),('kentucky','1263','mississippi river','black mountain','78'),('louisiana','163','new orleans','driskill mountain','-1'),('maine','1606','atlantic ocean','mount katahdin','0'),('maryland','1024','atlantic ocean','backbone mountain','0'),('massachusetts','1064','atlantic ocean','mount greylock','0'),('michigan','604','lake erie','mount curwood','174'),('minnesota','701','lake superior','eagle mountain','183'),('mississippi','246','gulf of mexico','woodall mountain','0'),('missouri','540','st. francis river','taum sauk mountain','70'),('montana','3901','kootenai river','granite peak','549'),('nebraska','1654','southeast corner','johnson township','256'),('nevada','4005','colorado river','boundary peak','143'),('new hampshire','1917','atlantic ocean','mount washington','0'),('new jersey','550','atlantic ocean','high point','0'),('new mexico','4011','red bluff reservoir','wheeler peak','859'),('new york','1629','atlantic ocean','mount marcy','0'),('north carolina','2037','atlantic ocean','mount mitchell','0'),('north dakota','1069','red river','white butte','229'),('ohio','472','ohio river','campbell hill','132'),('oklahoma','1516','little river','black mesa','87'),('oregon','3424','pacific ocean','mount hood','0'),('pennsylvania','979','delaware river','mount davis','0'),('rhode island','247','atlantic ocean','jerimoth hill','0'),('south carolina','1085','atlantic ocean','sassafras mountain','0'),('south dakota','2207','big stone lake','harney peak','284'),('tennessee','2025','mississippi river','clingmans dome','55'),('texas','2667','gulf of mexico','guadalupe peak','0'),('utah','4123','beaver dam creek','kings peak','610'),('vermont','1339','lake champlain','mount mansfield','29'),('virginia','1746','atlantic ocean','mount rogers','0'),('washington','4392','pacific ocean','mount rainier','0'),('west virginia','1482','potomac river','spruce knob','73'),('wisconsin','595','lake michigan','timms hill','177'),('wyoming','4202','belle fourche river','gannett peak','945');\n",
      "/*!40000 ALTER TABLE highlow ENABLE KEYS */;\n",
      "\n",
      "--\n",
      "-- Table structure for table lake\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS lake;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE lake (\n",
      "  lake_name text,\n",
      "  area double DEFAULT NULL,\n",
      "  country_name varchar(3) NOT NULL DEFAULT '',\n",
      "  state_name text\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table lake\n",
      "--\n",
      "/*!40000 ALTER TABLE lake DISABLE KEYS */;\n",
      "INSERT INTO lake VALUES ('iliamna',2675,'usa','alaska'),('becharof',1186,'usa','alaska'),('teshekpuk',816,'usa','alaska'),('naknek',630,'usa','alaska'),('salton sea',932,'usa','california'),('tahoe',497,'usa','california'),('okeechobee',1810,'usa','florida'),('michigan',58016,'usa','illinois'),('michigan',58016,'usa','indiana'),('pontchartrain',1632,'usa','louisiana'),('superior',82362,'usa','michigan'),('huron',59570,'usa','michigan'),('michigan',58016,'usa','michigan'),('erie',25667,'usa','michigan'),('st. clair',1119,'usa','michigan'),('superior',82362,'usa','minnesota'),('lake of the woods',4391,'usa','minnesota'),('red',1169,'usa','minnesota'),('rainy',932,'usa','minnesota'),('mille lacs',536,'usa','minnesota'),('flathead',510,'usa','montana'),('tahoe',497,'usa','nevada'),('erie',25667,'usa','new york'),('ontario',19684,'usa','new york'),('champlain',1114,'usa','new york'),('erie',25667,'usa','ohio'),('erie',25667,'usa','pennsylvania'),('great salt lake',5180,'usa','utah'),('champlain',1114,'usa','vermont'),('superior',82362,'usa','wisconsin'),('michigan',58016,'usa','wisconsin'),('winnebago',557,'usa','wisconsin');\n",
      "/*!40000 ALTER TABLE lake ENABLE KEYS */;\n",
      "\n",
      "--\n",
      "-- Table structure for table mountain\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS mountain;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE mountain (\n",
      "  mountain_name text,\n",
      "  mountain_altitude int(11) DEFAULT NULL,\n",
      "  country_name varchar(3) NOT NULL DEFAULT '',\n",
      "  state_name text\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table mountain\n",
      "--\n",
      "/*!40000 ALTER TABLE mountain DISABLE KEYS */;\n",
      "INSERT INTO mountain VALUES ('mckinley',6194,'usa','alaska'),('st. elias',5489,'usa','alaska'),('foraker',5304,'usa','alaska'),('bona',5044,'usa','alaska'),('blackburn',4996,'usa','alaska'),('kennedy',4964,'usa','alaska'),('sanford',4949,'usa','alaska'),('south buttress',4842,'usa','alaska'),('vancouver',4785,'usa','alaska'),('churchill',4766,'usa','alaska'),('fairweather',4663,'usa','alaska'),('hubbard',4577,'usa','alaska'),('bear',4520,'usa','alaska'),('east buttress',4490,'usa','alaska'),('hunter',4442,'usa','alaska'),('alverstone',4439,'usa','alaska'),('browne tower',4429,'usa','alaska'),('wrangell',4317,'usa','alaska'),('whitney',4418,'usa','california'),('williamson',4382,'usa','california'),('white',4342,'usa','california'),('north palisade',4341,'usa','california'),('shasta',4317,'usa','california'),('sill',4317,'usa','california'),('elbert',4399,'usa','colorado'),('massive',4396,'usa','colorado'),('harvard',4395,'usa','colorado'),('bianca',4372,'usa','colorado'),('la plata',4370,'usa','colorado'),('uncompahgre',4361,'usa','colorado'),('crestone',4357,'usa','colorado'),('lincoln',4354,'usa','colorado'),('grays',4349,'usa','colorado'),('antero',4349,'usa','colorado'),('torreys',4349,'usa','colorado'),('castle',4348,'usa','colorado'),('quandary',4348,'usa','colorado'),('evans',4348,'usa','colorado'),('longs',4345,'usa','colorado'),('wilson',4342,'usa','colorado'),('shavano',4337,'usa','colorado'),('belford',4327,'usa','colorado'),('princeton',4327,'usa','colorado'),('crestone needle',4327,'usa','colorado'),('yale',4327,'usa','colorado'),('bross',4320,'usa','colorado'),('kit carson',4317,'usa','colorado'),('el diente',4316,'usa','colorado'),('maroon',4315,'usa','colorado'),('rainier',4392,'usa','washington');\n",
      "/*!40000 ALTER TABLE mountain ENABLE KEYS */;\n",
      "\n",
      "--\n",
      "-- Table structure for table river\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS river;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE river (\n",
      "  river_name text,\n",
      "  length int(11) DEFAULT NULL,\n",
      "  country_name varchar(3) NOT NULL DEFAULT '',\n",
      "  traverse text\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table river\n",
      "--\n",
      "/*!40000 ALTER TABLE river DISABLE KEYS */;\n",
      "INSERT INTO river VALUES ('mississippi',3778,'usa','minnesota'),('mississippi',3778,'usa','wisconsin'),('mississippi',3778,'usa','iowa'),('mississippi',3778,'usa','illinois'),('mississippi',3778,'usa','missouri'),('mississippi',3778,'usa','kentucky'),('mississippi',3778,'usa','tennessee'),('mississippi',3778,'usa','arkansas'),('mississippi',3778,'usa','mississippi'),('mississippi',3778,'usa','louisiana'),('mississippi',3778,'usa','louisiana'),('missouri',3968,'usa','montana'),('missouri',3968,'usa','north dakota'),('missouri',3968,'usa','south dakota'),('missouri',3968,'usa','iowa'),('missouri',3968,'usa','nebraska'),('missouri',3968,'usa','missouri'),('missouri',3968,'usa','missouri'),('colorado',2333,'usa','colorado'),('colorado',2333,'usa','utah'),('colorado',2333,'usa','arizona'),('colorado',2333,'usa','nevada'),('colorado',2333,'usa','california'),('ohio',1569,'usa','pennsylvania'),('ohio',1569,'usa','west virginia'),('ohio',1569,'usa','kentucky'),('ohio',1569,'usa','indiana'),('ohio',1569,'usa','illinois'),('ohio',1569,'usa','illinois'),('ohio',1569,'usa','ohio'),('red',1638,'usa','new mexico'),('red',1638,'usa','texas'),('red',1638,'usa','oklahoma'),('red',1638,'usa','arkansas'),('red',1638,'usa','arkansas'),('red',1638,'usa','louisiana'),('arkansas',2333,'usa','colorado'),('arkansas',2333,'usa','kansas'),('arkansas',2333,'usa','oklahoma'),('arkansas',2333,'usa','arkansas'),('canadian',1458,'usa','colorado'),('canadian',1458,'usa','new mexico'),('canadian',1458,'usa','texas'),('canadian',1458,'usa','oklahoma'),('connecticut',655,'usa','new hampshire'),('connecticut',655,'usa','vermont'),('connecticut',655,'usa','massachusetts'),('connecticut',655,'usa','connecticut'),('delaware',451,'usa','new york'),('delaware',451,'usa','pennsylvania'),('delaware',451,'usa','new jersey'),('delaware',451,'usa','delaware'),('little missouri',901,'usa','wyoming'),('little missouri',901,'usa','montana'),('little missouri',901,'usa','south dakota'),('little missouri',901,'usa','north dakota'),('snake',1670,'usa','wyoming'),('snake',1670,'usa','idaho'),('snake',1670,'usa','oregon'),('snake',1670,'usa','washington'),('snake',1670,'usa','washington'),('chattahoochee',702,'usa','georgia'),('chattahoochee',702,'usa','georgia'),('chattahoochee',702,'usa','florida'),('cimarron',965,'usa','new mexico'),('cimarron',965,'usa','kansas'),('cimarron',965,'usa','oklahoma'),('green',1175,'usa','wyoming'),('green',1175,'usa','utah'),('green',1175,'usa','colorado'),('green',1175,'usa','utah'),('north platte',1094,'usa','colorado'),('north platte',1094,'usa','wyoming'),('north platte',1094,'usa','nebraska'),('potomac',462,'usa','west virginia'),('potomac',462,'usa','maryland'),('potomac',462,'usa','virginia'),('potomac',462,'usa','district of columbia'),('republican',679,'usa','colorado'),('republican',679,'usa','nebraska'),('republican',679,'usa','kansas'),('rio grande',3033,'usa','colorado'),('rio grande',3033,'usa','new mexico'),('rio grande',3033,'usa','texas'),('san juan',579,'usa','colorado'),('san juan',579,'usa','new mexico'),('san juan',579,'usa','colorado'),('san juan',579,'usa','utah'),('tennessee',1049,'usa','tennessee'),('tennessee',1049,'usa','alabama'),('tennessee',1049,'usa','tennessee'),('tennessee',1049,'usa','kentucky'),('wabash',764,'usa','ohio'),('wabash',764,'usa','indiana'),('wabash',764,'usa','illinois'),('yellowstone',1080,'usa','wyoming'),('yellowstone',1080,'usa','montana'),('yellowstone',1080,'usa','north dakota'),('allegheny',523,'usa','pennsylvania'),('allegheny',523,'usa','new york'),('allegheny',523,'usa','pennsylvania'),('bighorn',541,'usa','wyoming'),('bighorn',541,'usa','montana'),('cheyenne',848,'usa','wyoming'),('cheyenne',848,'usa','north dakota'),('clark fork',483,'usa','montana'),('clark fork',483,'usa','idaho'),('columbia',1953,'usa','washington'),('columbia',1953,'usa','oregon'),('cumberland',1105,'usa','kentucky'),('cumberland',1105,'usa','tennessee'),('cumberland',1105,'usa','kentucky'),('dakota',1142,'usa','north dakota'),('dakota',1142,'usa','south dakota'),('gila',805,'usa','new mexico'),('gila',805,'usa','arizona'),('hudson',492,'usa','new york'),('hudson',492,'usa','new jersey'),('neosho',740,'usa','kansas'),('neosho',740,'usa','oklahoma'),('niobrara',693,'usa','wyoming'),('niobrara',693,'usa','nebraska'),('ouachita',973,'usa','arkansas'),('ouachita',973,'usa','louisiana'),('pearl',788,'usa','michigan'),('pearl',788,'usa','louisiana'),('pecos',805,'usa','new mexico'),('pecos',805,'usa','texas'),('powder',603,'usa','wyoming'),('powder',603,'usa','montana'),('roanoke',660,'usa','virginia'),('roanoke',660,'usa','north carolina'),('rock',459,'usa','wisconsin'),('rock',459,'usa','illinois'),('smoky hill',869,'usa','colorado'),('smoky hill',869,'usa','kansas'),('south platte',682,'usa','colorado'),('south platte',682,'usa','nebraska'),('st. francis',684,'usa','missouri'),('st. francis',684,'usa','arkansas'),('tombigbee',658,'usa','mississippi'),('tombigbee',658,'usa','alabama'),('washita',805,'usa','texas'),('washita',805,'usa','oklahoma'),('wateree catawba',636,'usa','north carolina'),('wateree catawba',636,'usa','south carolina'),('white',1110,'usa','arkansas'),('white',1110,'usa','missouri'),('white',1110,'usa','arkansas');\n",
      "/*!40000 ALTER TABLE river ENABLE KEYS */;\n",
      "\n",
      "--\n",
      "-- Table structure for table state\n",
      "--\n",
      "\n",
      "DROP TABLE IF EXISTS state;\n",
      "/*!40101 SET @saved_cs_client     = @@character_set_client */;\n",
      "/*!40101 SET character_set_client = utf8 */;\n",
      "CREATE TABLE state (\n",
      "  state_name text,\n",
      "  population int(11) DEFAULT NULL,\n",
      "  area double DEFAULT NULL,\n",
      "  country_name varchar(3) NOT NULL DEFAULT '',\n",
      "  capital text,\n",
      "  density double DEFAULT NULL\n",
      ");\n",
      "/*!40101 SET character_set_client = @saved_cs_client */;\n",
      "\n",
      "--\n",
      "-- Dumping data for table state\n",
      "--\n",
      "/*!40000 ALTER TABLE state DISABLE KEYS */;\n",
      "INSERT INTO state VALUES ('alabama',3894000,51700,'usa','montgomery',75.31914893617021),('alaska',401800,591000,'usa','juneau',0.6798646362098139),('arizona',2718000,114000,'usa','phoenix',23.842105263157894),('arkansas',2286000,53200,'usa','little rock',42.96992481203007),('california',23670000,158000,'usa','sacramento',149.81012658227849),('colorado',2889000,104000,'usa','denver',27.778846153846153),('connecticut',3107000,5020,'usa','hartford',618.9243027888447),('delaware',594000,2044,'usa','dover',290.60665362035223),('district of columbia',638000,1100,'usa','washington',580),('florida',9746000,68664,'usa','tallahassee',141.9375509728533),('georgia',5463000,58900,'usa','atlanta',92.75042444821732),('hawaii',964000,6471,'usa','honolulu',148.97233812393756),('idaho',944000,83000,'usa','boise',11.373493975903614),('illinois',11400000,56300,'usa','springfield',202.4866785079929),('indiana',5490000,36200,'usa','indianapolis',151.65745856353593),('iowa',2913000,56300,'usa','des moines',51.740674955595026),('kansas',2364000,82300,'usa','topeka',28.724179829890645),('kentucky',2364000,82300,'usa','frankfort',28.724179829890645),('louisiana',4206000,47700,'usa','baton rouge',88.17610062893081),('maine',1125000,33265,'usa','augusta',33.81932962573275),('maryland',4217000,10460,'usa','annapolis',403.1548757170172),('massachusetts',5737000,8284,'usa','boston',692.5398358281024),('michigan',9262000,58500,'usa','lansing',158.32478632478632),('minnesota',4076000,84400,'usa','st. paul',48.29383886255924),('mississippi',2520000,47700,'usa','jackson',52.83018867924528),('missouri',4916000,69700,'usa','jefferson city',70.53084648493544),('montana',786700,147000,'usa','helena',5.351700680272109),('nebraska',1569000,77300,'usa','lincoln',20.297542043984475),('nevada',800500,110500,'usa','carson city',7.244343891402715),('new hampshire',920600,9279,'usa','concord',99.21327729281172),('new jersey',7365000,7787,'usa','trenton',945.8071144214717),('new mexico',1303000,121600,'usa','santa fe',10.71546052631579),('new york',17558000,49100,'usa','albany',357.5967413441955),('north carolina',5882000,52670,'usa','raleigh',111.67647617239415),('north dakota',652700,70700,'usa','bismarck',9.231966053748232),('ohio',10800000,41300,'usa','columbus',261.50121065375305),('oklahoma',3025000,69950,'usa','oklahoma city',43.24517512508935),('oregon',2633000,97073,'usa','salem',27.12391705211542),('pennsylvania',11863000,45308,'usa','harrisburg',261.8301403725611),('rhode island',947200,1212,'usa','providence',781.5181518151816),('south carolina',3121800,31113,'usa','columbia',100.3374795101726),('south dakota',690767,77116,'usa','pierre',8.957505576015354),('tennessee',4591000,42140,'usa','nashville',108.94636924537257),('texas',14229000,266807,'usa','austin',53.33068472716233),('utah',1461000,84900,'usa','salt lake city',17.208480565371026),('vermont',511500,9614,'usa','montpelier',53.203661327231124),('virginia',5346800,40760,'usa','richmond',131.1776251226693),('washington',4113200,68139,'usa','olympia',60.36484245439469),('west virginia',1950000,24200,'usa','charleston',80.57851239669421),('wisconsin',4700000,56153,'usa','madison',83.69989136822609),('wyoming',469557,97809,'usa','cheyenne',4.8007545317915525);\n",
      "/*!40000 ALTER TABLE state ENABLE KEYS */;\n",
      "/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;\n",
      "\n",
      "/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;\n",
      "/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;\n",
      "/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;\n",
      "/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;\n",
      "/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;\n",
      "/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;\n",
      "/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;\n",
      "\n",
      "-- Dump completed on 2017-04-12 17:54:35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# !wget https://github.com/jkkummerfeld/text2sql-data/raw/master/data/geography.json\n",
    "# !wget https://github.com/jkkummerfeld/text2sql-data/raw/master/data/geography-db.sql\n",
    "\n",
    "import re\n",
    "import sqlite3\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "DATABASE_NAME = 'geo.db'\n",
    "SQL_FILENAME = 'geography-db.sql'\n",
    "DATASET_FILENAME = 'geography.json'\n",
    "\n",
    "with open(SQL_FILENAME, 'r') as file:\n",
    "    sql_script = file.read()\n",
    "    sql_script = re.sub(r\"\\s*ENGINE=[^ ]+\",\"\", sql_script)\n",
    "    sql_script = re.sub(r\"\\s*DEFAULT CHARSET=[^ ;]+\",\"\", sql_script)\n",
    "    sql_script = re.sub(r\"\\s*LOCK TABLES `[^`]+` WRITE;\",\"\", sql_script)  # remove LOCK TABLES\n",
    "    sql_script = re.sub(r\"\\s*UNLOCK TABLES;\",\"\", sql_script)  # remove UNLOCK TABLES\n",
    "    sql_script = sql_script.replace('`', '')  # remove backticks\n",
    "\n",
    "# Connect to the SQLite database (this will create the file if it doesn't exist)\n",
    "connection = sqlite3.connect(DATABASE_NAME)\n",
    "print(sql_script)\n",
    "\n",
    "connection.executescript(sql_script)\n",
    "connection.commit()\n",
    "connection.close()\n",
    "\n",
    "connection = sqlite3.connect(DATABASE_NAME)\n",
    "cursor = connection.cursor()\n",
    "with open(DATASET_FILENAME, 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "splits = {'train': [], 'dev': [], 'test': []}\n",
    "for query_type in dataset:\n",
    "    for example in query_type['sentences']:\n",
    "        split = example['question-split']\n",
    "        example['question'] = example['text']\n",
    "        for key, value in example['variables'].items():\n",
    "            example['question'] = example['question'].replace(key, value)\n",
    "        example['sql'] = deepcopy(query_type['sql'])\n",
    "        example['sql'] = example['sql'][0]\n",
    "        for key, value in example['variables'].items():\n",
    "            example['sql'] = example['sql'].replace(key, value)\n",
    "        try:\n",
    "            cursor.execute(example['sql'])\n",
    "        except:\n",
    "            continue\n",
    "        example['db_answer'] = cursor.fetchall()\n",
    "        del example['text']\n",
    "        del example['variables']\n",
    "        splits[split].append(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a function you can use to query the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.082603Z",
     "start_time": "2023-10-27T03:34:01.039904Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_db(sql):\n",
    "    connection = sqlite3.connect(DATABASE_NAME)\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchall()\n",
    "    connection.close()\n",
    "    return result\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is pretty small:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.085032Z",
     "start_time": "2023-10-27T03:34:01.082786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 547\n",
      "Dev set size: 48\n",
      "Test set size: 277\n"
     ]
    }
   ],
   "source": [
    "print('Train set size:', len(splits['train']))\n",
    "print('Dev set size:', len(splits['dev']))\n",
    "print('Test set size:', len(splits['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect an example from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.085194Z",
     "start_time": "2023-10-27T03:34:01.082935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question-split': 'train',\n",
       " 'question': 'what is the biggest city in nebraska',\n",
       " 'sql': 'SELECT CITYalias0.CITY_NAME FROM CITY AS CITYalias0 WHERE CITYalias0.POPULATION = ( SELECT MAX( CITYalias1.POPULATION ) FROM CITY AS CITYalias1 WHERE CITYalias1.STATE_NAME = \"nebraska\" ) AND CITYalias0.STATE_NAME = \"nebraska\" ;',\n",
       " 'db_answer': [('omaha',)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `db_answer` is the result of executing the given SQL output against the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.157941Z",
     "start_time": "2023-10-27T03:34:01.083057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('omaha',)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_db(splits['train'][0]['sql'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how well our language model does on this text-to-SQL task out of the box. You can just use greedy decoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.158134Z",
     "start_time": "2023-10-27T03:34:01.126369Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Write a SQL query based on the following question.\\n\\nQuestion: {input}\\n\\nSQL:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.158193Z",
     "start_time": "2023-10-27T03:34:01.126533Z"
    }
   },
   "outputs": [],
   "source": [
    "eg_data = splits['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:01.900161Z",
     "start_time": "2023-10-27T03:34:01.126635Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT city FROM city WHERE city.name = 'Nebraska' AND city.zipcode = '9';\n"
     ]
    }
   ],
   "source": [
    "# Your code here. Generate from the model using greedy decoding with the above prompt\n",
    "generation_config = GenerationConfig.from_pretrained(model_name,max_length=50,temperature=1e-6,do_sample=True)\n",
    "inputs = prompt.format(input=eg_data['question'])\n",
    "inputs = tokenizer(inputs, return_tensors=\"pt\").input_ids.cuda()\n",
    "\n",
    "predicted_sql = gpt2_model.generate(inputs,generation_config).squeeze(0)\n",
    "predicted_sql = tokenizer.decode(predicted_sql, skip_special_tokens=True).split('SQL: ')[-1].split(';')[0].strip() + ';'\n",
    "print(predicted_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get something that looks kind of like a SQL query, but it probably won't match the correct output, and in fact it most likely won't even execute without crashing when you try to query the database (you'll see a syntax error below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:06.659166Z",
     "start_time": "2023-10-27T03:34:06.658744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to execute!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query_db(predicted_sql)\n",
    "    print('success!')\n",
    "except:\n",
    "    print('failed to execute!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm quantitatively that the model doesn't work well out-of-the-box by running on the dev dataset (`splits['dev']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:39:00.080564Z",
     "start_time": "2023-10-27T03:39:00.077909Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_greedy(model, data, max_new_tokens=128):\n",
    "    \"\"\"\n",
    "    Return the model's greedy text-to-sql predictions on the given data split.\n",
    "    The maximum number of new tokens generated (NOT including tokens in the prompt) should be equal to max_new_tokens.\n",
    "    For speed, you should batch the generation. The tokenizer can handle multiple inputs simultaneously,\n",
    "    but you'll need to tell it to pad using padding=True, and you may also need to set tokenizer.padding_side='left'.\n",
    "    Hint: as a postprocessing step after you're done, you may need to cut off the output at the first appearance of '\\n' if the output is continuing past the end of the SQL.\n",
    "    \"\"\"\n",
    "    questions = [d['question'] for d in data]\n",
    "    predicted_sqls = []\n",
    "    tokenizer.padding_side='left'\n",
    "    generation_config = GenerationConfig.from_pretrained(model_name,max_new_tokens=max_new_tokens,temperature=0.1,do_sample=True)\n",
    "\n",
    "    # Your code here\n",
    "    prompts = [prompt.format(input=q) for q in questions]\n",
    "    prompts = tokenizer(prompts, return_tensors=\"pt\",padding=True)\n",
    "    att_mask = prompts.attention_mask.cuda()\n",
    "    prompts = prompts.input_ids.cuda()\n",
    "    outputs = model.generate(prompts,generation_config,attention_mask = att_mask).cpu()\n",
    "    predicted_sqls = [tokenizer.decode(op, skip_special_tokens=True) for op in outputs]\n",
    "    predicted_sqls = [sql.split('SQL:')[-1].split('\\n')[0] for sql in predicted_sqls]\n",
    "    # print(predicted_sqls)\n",
    "    return predicted_sqls # list of strings containing SQL predictions for each question in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:10.320225Z",
     "start_time": "2023-10-27T03:34:09.961132Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_execution_accuracy(predictions, data):\n",
    "    assert len(predictions) == len(data)\n",
    "    correct = 0\n",
    "    for p, d in zip(predictions, data):\n",
    "        try:\n",
    "            if query_db(p) == d['db_answer']:\n",
    "                correct += 1\n",
    "        except: # failed to execute\n",
    "            pass\n",
    "    return correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:19.332029Z",
     "start_time": "2023-10-27T03:34:16.484657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example prediction:  SELECT * FROM area WHERE area.name = 'california'\n",
      "initial execution acc 0.0\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_greedy(gpt2_model, splits['dev'])\n",
    "print('example prediction:', predictions[5])\n",
    "print('initial execution acc', check_execution_accuracy(predictions, splits['dev']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:34:19.332256Z",
     "start_time": "2023-10-27T03:34:19.329764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably observe an accuracy around 0-2%. (It may be hard to verify if your `predict_greedy` function is correct at this stage, because the expected accuracy is so low, but you will reuse it later with an improved model, at which point it will be more obvious if your implementation is correct.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's prepare our dataset for finetuning (i.e., training our pretrained language model on this text-to-SQL training set). For each element in the dataset, it should have a text prompt and then the SQL output, similar to above. Your job is to fill in the labels field below. This field sets the labels to use for training during the language modeling task.\n",
    "\n",
    "For the labels, we only want to train the model to output the text after the word \"SQL:\". This is because in the prompt, everything before the word \"SQL:\" will also be provided to the model as input. Hint: use -100 as the label for tokens you do not want to train on. Hint 2: When doing LM training, the labels are the same as the input tokens, except shifted to the left by one. You should check whether Huggingface is already doing the shifting, or whether you need to do the shifting yourself.\n",
    "\n",
    "One thing to be careful of with all LMs is to make sure there are not extra spaces. So, the text should be formatted as like \"SQL: {sql output}\" not \"SQL: {sql output} \". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:36:49.452414Z",
     "start_time": "2023-10-27T03:36:49.451164Z"
    }
   },
   "outputs": [],
   "source": [
    "class Text2SQLDataset(Dataset):\n",
    "    PROMPT = \"Write a SQL query based on the following question.\\n\\nQuestion: {question}\\n\\nSQL: {sql}\"\n",
    "\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        tokenizer.padding_side = 'right'\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.labels = []\n",
    "\n",
    "        training_texts = []\n",
    "        for example in self.data:\n",
    "            training_text = Text2SQLDataset.PROMPT.format(question=example['question'], sql=example['sql']) + \"<|endoftext|>\" # include the end token so model knows when to stop!\n",
    "            training_texts.append(training_text)\n",
    "            \n",
    "        encodings_dict = self.tokenizer(training_texts, padding=True, truncation=True)\n",
    "        for i, (example, training_text) in enumerate(zip(data, training_texts)):\n",
    "            input_ids = torch.tensor(encodings_dict['input_ids'][i])\n",
    "            self.input_ids.append(input_ids)\n",
    "            \n",
    "            attn_masks = torch.tensor(encodings_dict['attention_mask'][i])\n",
    "            self.attn_masks.append(attn_masks)\n",
    "            \n",
    "            # Your code here\n",
    "            sql = tokenizer(example['sql'] + \"<|endoftext|>\")['input_ids']\n",
    "            length = attn_masks.sum()\n",
    "            while len(sql) < length:\n",
    "                sql = [-100] + sql\n",
    "\n",
    "            while len(sql) < input_ids.shape[0]:\n",
    "                # sql = sql + [tokenizer.pad_token_id]\n",
    "                sql = sql + [-100]\n",
    "\n",
    "            self.labels.append(torch.tensor(sql))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = {\n",
    "            'input_ids':self.input_ids[idx], \n",
    "            'attention_mask':self.attn_masks[idx], \n",
    "            'labels':self.labels[idx]\n",
    "        }\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:36:58.515163Z",
     "start_time": "2023-10-27T03:36:57.381469Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Text2SQLDataset(splits['train'], tokenizer)\n",
    "dev_dataset = Text2SQLDataset(splits['dev'], tokenizer)\n",
    "test_dataset = Text2SQLDataset(splits['test'], tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the Huggingface Trainer to finetune GPT-2 Medium on this dataset. This abstracts away all of the details of training. Setup the training arguments to perform 3 epochs of training on this dataset, use a per-device batch size of 2 with gradient accumulation set to 8, use 30 warmup steps, a weight decay of 0.05. Set the eval batch size to be 8. Save a checkpoint after 100 steps. Set fp16 to True. Save the checkpoint in a specific output_dir so you can load it later. Hint: if it tries to launch Wandb, you may add the argument report_to=\"none\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:40:58.791419Z",
     "start_time": "2023-10-27T03:39:35.334425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from transformers import Trainer,TrainingArguments,DataCollatorForLanguageModeling\n",
    "\n",
    "# Tr_args = TrainingArguments(output_dir='gpt2_finetuned.ckpredict_greedypt',\n",
    "#                             overwrite_output_dir=True,\n",
    "#                             do_train=True,\n",
    "#                             do_eval=True,\n",
    "#                             gradient_accumulation_steps=8,\n",
    "#                             warmup_steps = 30,\n",
    "#                             per_device_train_batch_size = 2,\n",
    "#                             weight_decay = 0.05,\n",
    "#                             save_steps=100,\n",
    "#                             fp16=True,\n",
    "#                             report_to=\"none\")\n",
    "\n",
    "# GPT_Trainer = Trainer(gpt2_model,\n",
    "#                       args=Tr_args,\n",
    "#                       train_dataset=train_dataset,\n",
    "#                       eval_dataset=dev_dataset,\n",
    "#                       )\n",
    "# GPT_Trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the final saved version of the model below. You may need to delete the previously loaded model if you run out of GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:41:13.659314Z",
     "start_time": "2023-10-27T03:41:07.391652Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_model.cpu()\n",
    "# Your code here\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained('./gpt2_finetuned.ckpt/checkpoint-100').cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our finetuned model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:41:38.455064Z",
     "start_time": "2023-10-27T03:41:19.167285Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT CITYalias0.CITY_NAME FROM CITY AS CITYalias0 WHERE CITYalias0.POPULATION = ( SELECT MAX( CITYalias1.POPULATION ) FROM CITY AS CITYalias1 WHERE CITYalias1.STATE_NAME = \"kansas\" ) AND CITYalias0.STATE_NAME = \"kansas\" ;\n",
      "finetuned execution acc: 0.5018050541516246\n"
     ]
    }
   ],
   "source": [
    "finetuned_predictions = predict_greedy(finetuned_model, splits['test'])\n",
    "print(finetuned_predictions[0])\n",
    "print('finetuned execution acc:', check_execution_accuracy(finetuned_predictions, splits['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should achieve an accuracy of roughly 50% using the suggested training hyperparameters; we will check >40% in the autograder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:41:48.757583Z",
     "start_time": "2023-10-27T03:41:48.756934Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write('\\n'.join(predictions))\n",
    "\n",
    "# save_predictions(finetuned_predictions, 'finetuned_predictions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect some of your predictions compared to the correct outputs, and describe some common types of errors in your report. What fraction of errors are due to failing to execute (e.g., syntax error), and what fraction are due to executing but getting the wrong answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:45:31.091569Z",
     "start_time": "2023-10-27T03:45:29.037326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for sql in finetuned_predictions:\n",
    "    try:\n",
    "        query_db(sql)\n",
    "        with open('right_sql_fintuned.txt','a')as f:\n",
    "            f.write(sql+'\\n')\n",
    "    except:\n",
    "        with open('wrong_sql_fintuned.txt','a')as f:\n",
    "            f.write(sql+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also examine the exact match accuracy (i.e., requiring the predicted SQL string to exactly match the gold answer) rather than the execution accuracy (just checking whether the output of executing the SQL against the database is the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:45:36.993930Z",
     "start_time": "2023-10-27T03:45:36.989014Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_exact_match_accuracy(predictions, data):\n",
    "    assert len(predictions) == len(data)\n",
    "    correct = 0\n",
    "    for p, d in zip(predictions, data):\n",
    "        if p == d['sql']:\n",
    "            correct += 1\n",
    "    return correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:45:44.165863Z",
     "start_time": "2023-10-27T03:45:44.165481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finetuned exact match acc: 0.4368231046931408\n"
     ]
    }
   ],
   "source": [
    "print('finetuned exact match acc:', check_exact_match_accuracy(finetuned_predictions, splits['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact match accuracy will likely be close to the execution accuracy, but not exactly the same. What are some potential pros and cons of each metric? Discuss in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unload your finetuned model so that you don't run out of GPU memory later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T03:50:47.284070Z",
     "start_time": "2023-10-27T03:50:47.282716Z"
    }
   },
   "outputs": [],
   "source": [
    "finetuned_model.cpu()\n",
    "del finetuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final part of this project, you will explore few-shot prompting, i.e., simply prompting the pretrained language model out-of-the-box using a small number of examples rather than finetuning.\n",
    "\n",
    "First, let's try just selecting 4 examples completely at random from the training set. Rewrite your `predict_greedy` function to change the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T04:11:32.376906Z",
     "start_time": "2023-10-27T04:11:32.376422Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "few_shot_prompt = \"Question: {question0}\\n\\nSQL: {sql0}\\n\\n\\n\\n\" + \\\n",
    "    \"Question: {question1}\\n\\nSQL: {sql1}\\n\\n\\n\\n\" + \\\n",
    "    \"Question: {question2}\\n\\nSQL: {sql2}\\n\\n\\n\\n\" + \\\n",
    "    \"Question: {question3}\\n\\nSQL: {sql3}\\n\\n\\n\\n\" + \\\n",
    "    \"Question: {question}\\n\\nSQL:\"\n",
    "\n",
    "\n",
    "def select_random_examples(question, few_shot_data, num_examples=4):\n",
    "    \"\"\"\n",
    "    Return a list containing 4 of the elements of few_shot_data, selected randomly\n",
    "    \"\"\"\n",
    "    return random.sample(few_shot_data, num_examples)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_greedy_fewshot(model, data, few_shot_data, max_new_tokens=128, example_selection_method=select_random_examples):\n",
    "    \"\"\"\n",
    "    Return the model's greedy text-to-sql predictions on the given data split.\n",
    "    The maximum number of new tokens generated (NOT including tokens in the prompt) should be equal to max_new_tokens.\n",
    "    The four examples with their SQL outputs should go in {question1}, {sql1}, {question2}, {sql2}, etc. in the few_shot_prompt. \n",
    "    The final {question} is the question that we're currently evaluating on.\n",
    "    \"\"\"\n",
    "    questions = [d['question'] for d in data]\n",
    "    predicted_sqls = []\n",
    "    prompts = []\n",
    "    for question in questions:\n",
    "        few_shot_examples = example_selection_method(question, few_shot_data, num_examples=4)\n",
    "        prompts.append(few_shot_prompt.format(\n",
    "            question0=few_shot_examples[0]['question'],\n",
    "            sql0=few_shot_examples[0]['sql'],\n",
    "            question1=few_shot_examples[1]['question'],\n",
    "            sql1=few_shot_examples[1]['sql'],\n",
    "            question2=few_shot_examples[2]['question'],\n",
    "            sql2=few_shot_examples[2]['sql'],\n",
    "            question3=few_shot_examples[3]['question'],\n",
    "            sql3=few_shot_examples[3]['sql'],\n",
    "            question=question\n",
    "        ))\n",
    "    # Your code here; should be fairly similar to your previous predict_greedy code.\n",
    "    # Hint: if you batch, we recommend batch size 8-16.\n",
    "    generation_config = GenerationConfig.from_pretrained(model_name,max_new_tokens = max_new_tokens,temperature=1e-6,do_sample=True)\n",
    "\n",
    "    outputs = []\n",
    "    for seq_index in tqdm(range(len(prompts))):\n",
    "        input_id = tokenizer(prompts[seq_index], return_tensors=\"pt\",padding=False).input_ids.cuda()\n",
    "        output = model.generate(input_id,generation_config,pad_token_id=tokenizer.eos_token_id).cpu()\n",
    "        outputs.append(output.squeeze(0))\n",
    "        # print(tokenizer.decode(output.squeeze(0), skip_special_tokens=True).split('\\n\\n\\n\\n')[4].split('SQL:')[1].split('\\n')[0].strip())\n",
    "    predicted_sqls = [tokenizer.decode(op, skip_special_tokens=True) for op in outputs]\n",
    "    predicted_sqls = [sql.split('\\n\\n\\n\\n')[4].split('SQL:')[1].split('\\n')[0].strip() for sql in predicted_sqls]\n",
    "    return predicted_sqls # list of strings containing SQL predictions for each question in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T04:00:32.110513Z",
     "start_time": "2023-10-27T04:00:26.604793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload the gpt2 model if you need to\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(model_name).cuda() # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T04:13:31.061745Z",
     "start_time": "2023-10-27T04:11:37.292612Z"
    }
   },
   "outputs": [],
   "source": [
    "# This call can take a few minutes even if you batch; you can debug on a subset of the dev set as needed.\n",
    "predictions = predict_greedy_fewshot(gpt2_model, splits['test'], splits['train'])\n",
    "print('4-shot prompting with random examples, execution acc:', check_execution_accuracy(predictions, splits['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably observe between 0-5% accuracy. Random example selection doesn't work very well on this dataset. \n",
    "\n",
    "However, what if we select examples by picking the examples from the training set whose questions are most similar to our current question? To do this, load a pretrained sentence encoder, which takes a sentence as input and outputs a fixed-length vector encoding semantic information about that sentence. First compute the vectors associated with all the training set questions, and then select examples from the training set based on which question vectors have the largest dot products with the vector for your current question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T04:22:26.490348Z",
     "start_time": "2023-10-27T04:22:26.484944Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question-split': 'train',\n",
       " 'question': 'what is the biggest city in nebraska',\n",
       " 'sql': 'SELECT CITYalias0.CITY_NAME FROM CITY AS CITYalias0 WHERE CITYalias0.POPULATION = ( SELECT MAX( CITYalias1.POPULATION ) FROM CITY AS CITYalias1 WHERE CITYalias1.STATE_NAME = \"nebraska\" ) AND CITYalias0.STATE_NAME = \"nebraska\" ;',\n",
       " 'db_answer': [('omaha',)]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T04:28:37.815430Z",
     "start_time": "2023-10-27T04:28:37.535898Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Your code here; load the sentence encoder (see https://www.sbert.net/ for documentation). A good choice of model is \"all-MiniLM-L6-v2\"\n",
    "sentence_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "def compute_question_encodings(data):\n",
    "    \"\"\"\n",
    "    For each example in the data, add a field called 'question_encoding' to the example, which is the vector encoding of the question.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    vectors = sentence_encoder.encode([item['question'] for item in data])\n",
    "    for example, vector in zip(data, vectors):\n",
    "        example['question_encoding'] = np.array(vector)\n",
    "    return data\n",
    "\n",
    "\n",
    "def select_similar_examples(question, few_shot_data, num_examples=4):\n",
    "    \"\"\"\n",
    "    Return a list containing 4 of the elements of few_shot_data, selected with questions most semantically similar to the given question. \n",
    "    The most similar question should be the LAST element of the list, second most similar should be the second to last element, etc.\n",
    "    The reason is that in the few-shot prompt, **you want the best example to be the most recent one.**\n",
    "\n",
    "    To rank by semantic similarity, first compute the vector for the current question, then compute its dot product with\n",
    "    all training set vectors (hint: you may want to vectorize this computation using numpy). Then sort by dot product.\n",
    "\n",
    "    You should take advantage of the 'question_encoding' field that you added to each example in compute_question_encodings.\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    # hint: when you call .encode with your sentence encoder, use show_progress_bar=False to avoid tons of printouts\n",
    "    ques_vec = sentence_encoder.encode(question)\n",
    "    few_shot_data_ques_vectors = np.array([item['question_encoding'] for item in few_shot_data]).transpose()\n",
    "    values = np.dot(ques_vec,few_shot_data_ques_vectors)\n",
    "    \n",
    "    for index in range(len(few_shot_data)):\n",
    "        few_shot_data[index]['smilarity'] = values[index]\n",
    "    \n",
    "    few_shot_data.sort(key=lambda x:x['smilarity'])\n",
    "    few_shot_data.reverse()\n",
    "    \n",
    "    return few_shot_data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-27T04:28:51.309976Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# first precompute all the vectors for the training set\n",
    "a = compute_question_encodings(splits['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 272/277 [13:13<00:14,  2.91s/it]"
     ]
    }
   ],
   "source": [
    "# this call will again take a few minutes, even if you batched; feel free to debug on smaller sets of dev\n",
    "predictions = predict_greedy_fewshot(gpt2_model, splits['test'], splits['train'], example_selection_method=select_similar_examples)\n",
    "print('4-shot prompting with similar examples, execution acc:', check_execution_accuracy(predictions, splits['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now achieve about 34% accuracy. The autograder will check that you get >30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_predictions(predictions, 'similar4shot_predictions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, inspect some of your predictions (from prompting with similar examples) compared to the correct outputs, and describe some common types of errors in your report. Are there any differences compared to the finetuned model, or are the types of errors pretty similar? You can also check the exact match accuracy again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, do some open-ended exploration to try to improve your performance on this dataset as much as possible (whether for finetuning or prompting). No hard requirement on how much to improve (or to improve at all), but please discuss the ideas you tried + how effective they were in your report. (Be careful with the GPU memory if you're using Kaggle, though- we're already nearly capping out the GPU memory in a few places with the current settings.)\n",
    "\n",
    "A non-exhaustive list of possible ideas:\n",
    "* Use a different similarity metric for selecting examples in few-shot prompting\n",
    "* Use more examples in few-shot prompting\n",
    "* Load a different base model than GPT2-Medium, or look into calling the OpenAI API\n",
    "* Tune the hyperparameters used for finetuning\n",
    "* Try to combine few-shot prompting with finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your final submission should include the following files:\n",
    "\n",
    "* hw4.ipynb (this file; please rename to match)\n",
    "* finetuned_predictions.txt\n",
    "* similar4shot_predictions.txt\n",
    "* report.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
